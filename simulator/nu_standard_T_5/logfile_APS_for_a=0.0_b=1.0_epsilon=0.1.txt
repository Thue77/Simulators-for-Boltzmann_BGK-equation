
*********************************************************
***Python ml_test for APS method on 22-May-2021 11:54:25         ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[1.] and eps = 0.1  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 120000 samples and 12 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 5.0 0.0 0.495148256085515 0.0 10.038150065569734 0.0 1.1825766666667902e-06 0.0 0.0
1 2.5 0.003460772806828718 0.513243726841547 2.666015378728044 10.02513704565627 1.6919524999998714e-06 1.1797233333333898e-06 9.761101175261011 0.21209936979331895
2 1.25 -0.006409152083330076 0.49372560251292963 3.095833891762733 9.95281370857148 1.441326666666735e-06 1.4939241666667157e-06 6.501231541232596 0.18732544501983714
3 0.625 -0.000701268829612866 0.4879926207852712 3.3645692108227494 9.917080432858095 2.1252633333331754e-06 1.8609916666666966e-06 4.934167185859797 0.07139299290523646
4 0.3125 -0.0035225411881094773 0.49677554344388614 3.437921398889259 9.866121646607615 3.6983883333334688e-06 2.756183333333221e-06 3.887172527143781 0.1744662382931288
5 0.15625 0.005019937216236176 0.5050724546959888 3.455442393781651 9.78027622904886 6.346170833333176e-06 6.049630833333452e-06 3.529257716187956 0.046558397081539915
6 0.078125 -0.006949217366059498 0.5008602124085177 3.394522899473143 9.589797534100493 1.3153269166666467e-05 9.959120833333301e-06 3.2825077025962726 0.03917912538616789
7 0.0390625 -0.00396221700018369 0.49970227334512685 3.2225314477211526 9.237467004318002 2.616759249999999e-05 2.1772295000000005e-05 3.1185715825761045 0.040827375641501934
8 0.01953125 0.0028397442964377792 0.4840163179477499 2.9507449738571525 8.912021478260549 4.975634583333317e-05 3.8893245833333265e-05 3.10631583331999 0.27629224930193086
9 0.009765625 -0.0011069853259214526 0.5116298763302812 2.6009885956912657 8.808233868289173 0.0001022072025 7.706466499999973e-05 3.111948462029432 0.43832873712038306
10 0.0048828125 0.003796802681124323 0.4954325734147767 2.1336095183243153 8.97048346772627 0.00020775293833333338 0.00013723320833333345 3.1215994636825504 0.3109961025829165
11 0.00244140625 0.0010625328787642995 0.49776434036432976 1.5820210257419958 9.223377598254633 0.0003564083366666668 0.00026911956250000015 3.2158833681439845 0.02010443050162062

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.010000000000000002 ***
*********************************************************
alpha = 1.8372775400558143 (exponent for weak convergence) 
beta = 0.43152739209835805 (exponent for variance of bias estimate) 
gamma = 0.7786622012514899 (exponent for cost of bias estimate) 

