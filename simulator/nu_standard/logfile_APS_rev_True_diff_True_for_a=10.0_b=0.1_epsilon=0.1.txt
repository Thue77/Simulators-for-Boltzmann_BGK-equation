
*********************************************************
***Python ml_test for APS method on 25-May-2021 21:52:13         ***
***    Reverse splitting is used!!      ***
***    Altered diffusive coefficient is used!!      ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[5.1] and eps = 0.1  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 180000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.4963029836852644 0.0 2.4981640746038716 0.0 5.474583333334554e-07 0.0 0.0
1 0.5 0.0003827088379168429 0.49357927086527736 0.6854530397998281 1.644641524130726 1.9018555555555219e-06 6.544038888888634e-07 12.142879351811736 0.11902587363814836
2 0.25 0.0014324513244521565 0.4975891799705681 0.4567675850196125 1.1809626434557776 2.6173055555555023e-06 8.372816666666141e-07 10.477258835545095 0.11970681667474672
3 0.125 0.0011141088045634089 0.49943631054022386 0.31604609782464155 0.9105867000583936 4.366568333333336e-06 1.051512777777851e-06 9.077776597655093 0.03982291918596102
4 0.0625 0.0005872167563930783 0.49728427301717754 0.21843427697249834 0.7503772780777631 9.064498888888847e-06 1.6625822222222395e-06 8.174603164095991 0.16932380388365964
5 0.03125 0.000785057242605134 0.5022179146375659 0.1490454136645471 0.6481020666206746 1.706371888888884e-05 2.873837777777845e-06 7.95140257020662 0.28517120785135086
6 0.015625 -0.0011383112583597506 0.49874791579149247 0.11007193075324122 0.5882662998570884 3.415391000000001e-05 5.316756666666696e-06 7.674150100938663 0.17320607917794628
7 0.0078125 0.00020379776769150664 0.4974481607261491 0.10414366471451748 0.5385211428764654 6.682636166666664e-05 1.0144441666666637e-05 6.4030033143461464 0.11660544520048693
8 0.00390625 0.0013150631701374252 0.49967625360160933 0.12522488486430414 0.4876621186849289 0.00012928750277777767 1.9576406111111072e-05 4.936331907001412 0.07229510247043537
9 0.001953125 -0.00038177758953458914 0.4988198105064996 0.1549106433090449 0.43305025362357596 0.0002603229555555556 3.6750456666666605e-05 4.196118761776261 0.03835919242396153
10 0.0009765625 5.24461094811813e-05 0.4969596674579099 0.17166389768559143 0.3928756133518526 0.0005201105127777779 6.885276388888887e-05 4.064774304108444 0.1591825820811404
11 0.00048828125 0.0011174929608630487 0.5025565719240288 0.17131239580197916 0.3672367119999657 0.0010101988788888889 0.00013498997222222234 4.295764101295654 0.3846999506038164
12 0.000244140625 -0.00176643052504467 0.4956810039871365 0.16241860192068092 0.35661368311708086 0.0020082961088888885 0.00028222679722222194 4.696320744467016 0.44984957266084663
13 0.0001220703125 0.0003126875466836671 0.49781237356538055 0.15269427450713433 0.3520747417917963 0.003965032961111111 0.0005077621222222215 5.169256545984276 0.16265216976511876
14 6.103515625e-05 -0.0007573658902649825 0.49811623859897713 0.13694574709673693 0.3490945967459246 0.007662753278333333 0.0009850514016666674 5.617927157015508 0.09656069834850958
15 3.0517578125e-05 -0.00027146914418940676 0.497614080866983 0.12524478029629274 0.34995736731186733 0.015227898674444443 0.0019461809622222227 6.257605000371075 0.021235438265749727
16 1.52587890625e-05 -0.0011057676688057017 0.499929537894301 0.11272490608151806 0.34716985616466844 0.03038664074055556 0.003817650951111111 6.83331382843788 0.3190406570435058

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.010000000000000002 ***
*********************************************************
alpha = -0.28177215386610704 (exponent for weak convergence) 
beta = 0.10607898582977256 (exponent for variance of bias estimate) 
gamma = 0.9773331305722125 (exponent for cost of bias estimate) 

