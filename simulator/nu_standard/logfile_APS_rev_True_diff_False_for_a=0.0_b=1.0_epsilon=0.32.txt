
*********************************************************
***Python ml_test for APS method on 25-May-2021 17:44:13         ***
***    Reverse splitting is used!!      ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[1.] and eps = 0.32  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 180000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.4951807316008563 0.0 1.9227311332629957 0.0 6.356666666667207e-07 0.0 0.0
1 0.5 -0.0014544053842637159 0.49416274421771117 0.5995365007763517 1.8601061238182572 1.992406666666745e-06 6.153722222222374e-07 8.220694336684257 0.017509977984389392
2 0.25 -0.0015109720632707259 0.5002272812694639 0.55042670391538 1.7604590413310774 3.040943888888887e-06 7.941527777778863e-07 6.505514851655156 0.31210822275619027
3 0.125 -0.000796543071590154 0.50181251083442 0.5027385744929036 1.7065829151212608 4.881372777777749e-06 1.150879444444423e-06 6.170340273527519 0.10078119123410409
4 0.0625 -0.000435025338755267 0.50462710703565 0.44775994821962134 1.6757839727020227 9.246118888888925e-06 1.6870055555556244e-06 6.724760379063226 0.140538655165729
5 0.03125 -0.0009268169348899542 0.5022964341165654 0.3577464853200114 1.6941615959258072 1.7056529999999902e-05 2.9001977777778304e-06 9.112531872871882 0.0621541425017776
6 0.015625 0.0012719054960087747 0.5010140232595971 0.24371108723901733 1.735198827222535 3.3933704444444504e-05 5.501439999999944e-06 13.555241214220557 0.116057904149429
7 0.0078125 -0.0001237681105985283 0.5006773919781649 0.14416564010802002 1.766720669918938 6.528118111111113e-05 1.0087792777777812e-05 22.222198336548637 0.009947783059596102
8 0.00390625 0.00017901970663453237 0.5054257848462866 0.08077985933782592 1.7984040454792056 0.00012777951222222225 1.9898763888888896e-05 44.09944893387492 0.21872368628820082
9 0.001953125 0.000569093621175836 0.5018112415058057 0.044241872954662656 1.802174355685179 0.000253942043888889 3.901877833333316e-05 86.79840682445176 0.20445386874616087
10 0.0009765625 -4.9119912288168235e-05 0.4987881540095869 0.022425655487091658 1.8202404700076402 0.0005094984094444443 6.43379038888888e-05 144.8050806825331 0.14802125756423698
11 0.00048828125 -0.00037097897311380606 0.5003906181651379 0.012227536428478136 1.8269739747382885 0.001001944795 0.0001285964450000001 385.00211609012524 0.09926986323070111
12 0.000244140625 9.574710512103329e-05 0.5024529088730981 0.005579026533731523 1.8270719001301727 0.0019942464744444445 0.00026427263277777795 579.5332463643899 0.10011056369803786
13 0.0001220703125 0.00016034819802836147 0.499731900955869 0.0031627739045045717 1.8160582287752651 0.0039751464344444445 0.0005110331083333332 1235.6909145674872 0.14787840914602393
14 6.103515625e-05 0.0001114394612609585 0.5004520611878915 0.0013066224378779977 1.8305637999111894 0.007938932374444443 0.001025225267777777 1373.0215485871697 0.03145568667299494
15 3.0517578125e-05 -4.7687405854935426e-05 0.49897246089165137 0.0008140038913634063 1.8201818312638685 0.015927289804444442 0.002044467126111109 5963.9582498703185 0.07415914807125876
16 1.52587890625e-05 -4.6801068136300104e-05 0.5010447418389364 0.00034027688632799026 1.8299354997720954 0.03255461057944445 0.003858453402777775 6819.957163573406 0.11016401693310202

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.1024 ***
*********************************************************
alpha = 0.3380100751760506 (exponent for weak convergence) 
beta = 0.9271408292711488 (exponent for variance of bias estimate) 
gamma = 0.9892567988117561 (exponent for cost of bias estimate) 

