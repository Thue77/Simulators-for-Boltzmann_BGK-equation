
*********************************************************
***Python ml_test for APS method on 22-May-2021 03:37:59         ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[5.1] and eps = 0.032  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 180000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.5020029626527077 0.0 2.506356707930152 0.0 7.428911111111979e-07 0.0 0.0
1 0.5 -0.004649940998821224 0.49888417923808437 1.0154695166889636 1.7485926711033535 8.419855555556824e-07 6.588350000000847e-07 18.81316716480504 0.05533542370783665
2 0.25 0.002241127249244671 0.5012127304002895 0.8128170181115705 1.3096477580229364 8.850422222221729e-07 7.978088888888538e-07 15.548674434967586 0.003670571918593306
3 0.125 -0.0007759143822285005 0.4999213483831521 0.667909797678855 1.051695415269488 1.3183466666667304e-06 1.1100416666666193e-06 11.414356537009876 0.02440367921446638
4 0.0625 0.00015233229331470418 0.5013749507852608 0.5663894145282424 0.8891550805211366 2.0818266666666256e-06 1.6207494444444532e-06 8.311408016204508 0.06763075288416145
5 0.03125 0.0018164757538521735 0.49826584878264485 0.4976073508388237 0.7772707662790483 3.610992222222246e-06 2.171262777777806e-06 6.3705935458065115 0.27532960306334686
6 0.015625 -0.000731631080826826 0.499914446024892 0.4290478648800366 0.7025706208504754 6.360238333333375e-06 3.9560361111110606e-06 5.107328862941886 0.14174211540834492
7 0.0078125 0.00019901147312142138 0.5007520085786309 0.3734733141651097 0.6518523239889364 1.1272654999999985e-05 7.683138888888882e-06 4.414051391346001 0.04001640961893478
8 0.00390625 -0.0007030261945378919 0.5022963477190356 0.3290718414090216 0.6137616780024094 2.0855704444444474e-05 1.552121833333335e-05 4.084103314697686 0.14683883112492274
9 0.001953125 5.3885223905410546e-05 0.4974918400811782 0.2841722722535374 0.584177213671129 4.032773222222217e-05 3.048126055555558e-05 3.990809965922327 0.33019661083638097
10 0.0009765625 0.0013740100352438247 0.5030474864796426 0.24947654578225503 0.5459259107692774 8.542479944444447e-05 6.157861666666666e-05 3.9255264030441754 0.29529373070776044
11 0.00048828125 0.0016735881607494655 0.5010815844265829 0.21674845055512462 0.5005064499837764 0.00017052179000000004 0.00012310429777777777 3.8552659284504998 0.2692101602331056
12 0.000244140625 -0.0010780008052309197 0.4979270169578496 0.18657503511887216 0.44815236252682816 0.0003514571522222222 0.0002456114005555555 3.8749869407983506 0.16235225735593117
13 0.0001220703125 -0.0009914558225570848 0.49887702851582777 0.15576123203682143 0.4025031380971936 0.0006788453922222222 0.0004918800027777776 4.1986477154829895 0.1616477013862074
14 6.103515625e-05 0.0009488794871932887 0.4968621826335065 0.13493385496276558 0.3768139574809727 0.0012888003855555552 0.0009628697711111113 4.95021152259282 0.2594266981769848
15 3.0517578125e-05 0.0013799685285665376 0.5010471712354068 0.11650899748149647 0.36148509053113187 0.002533254489444444 0.0019098450666666666 5.9499122697223905 0.254872840462347
16 1.52587890625e-05 0.0002326817162152846 0.4989565857313976 0.1040978083744872 0.3546525202767516 0.004998190067777778 0.0038382172755555555 6.88828197556699 0.21624223486056257

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.001024 ***
*********************************************************
alpha = 1.0139335092408268 (exponent for weak convergence) 
beta = 0.18715633568504234 (exponent for variance of bias estimate) 
gamma = 0.9776884667717313 (exponent for cost of bias estimate) 

