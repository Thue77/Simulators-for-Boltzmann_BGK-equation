
*********************************************************
***Python ml_test for APS method on 25-May-2021 19:07:07         ***
***    Reverse splitting is used!!      ***
***    Altered diffusive coefficient is used!!      ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[1.] and eps = 0.1  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 180000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.5013698619529157 0.0 2.028181570663428 0.0 6.984294444443941e-07 0.0 0.0
1 0.5 6.437127390439433e-05 0.5022313806750957 0.002173776365799555 2.006663937315837 2.1095505555556494e-06 6.750900000000115e-07 9.201653854047487 0.0390442116325611
2 0.25 -0.0002089111481033788 0.4953966630206378 0.005156644566418088 1.9962485184701884 2.893447222222218e-06 8.108949999999658e-07 6.933896873734495 0.3229732047762001
3 0.125 0.00030923085499375084 0.4943378296346414 0.013285358077319247 1.9520961668589454 4.959178333333409e-06 1.1318644444444538e-06 5.61830529266619 0.06613748149886267
4 0.0625 -0.00034060706135249225 0.5002997794436579 0.03466687595057445 1.9142017333507155 8.982735555555463e-06 1.6661777777778515e-06 4.2053808181104975 0.3004188422369312
5 0.03125 8.947142535284824e-05 0.501145522101218 0.08536965937270538 1.8388285171612657 1.7212571111111152e-05 3.0239372222221938e-06 3.739837516474407 0.03527747601792489
6 0.015625 -0.0008718446044682996 0.49637465313085033 0.17455749174956586 1.7823574197210106 3.385701055555559e-05 5.6878338888889205e-06 3.510256283034356 0.17736436202491335
7 0.0078125 -0.0019850884781249796 0.4965604043229117 0.2808783826737599 1.778254900214392 6.62748211111111e-05 1.0199612777777862e-05 3.5142303165909823 0.0959822143430835
8 0.00390625 0.00010428913250258063 0.5017872050015556 0.32440550421407577 1.812382715799703 0.00013209621944444442 2.060956333333333e-05 3.6781190956074203 0.22294855640047245
9 0.001953125 -0.0005646745510551253 0.4999988868342469 0.2817373507698001 1.8785421723676903 0.00026051037222222227 3.480112277777765e-05 4.141015435094111 0.05328470572001131
10 0.0009765625 -0.0022834917279964595 0.503374230517931 0.19467900639235367 1.9302552928375905 0.0005102388461111112 6.855549666666654e-05 5.050125037659043 0.24999693821064342
11 0.00048828125 -0.0011870386486526909 0.5020646628052737 0.11532314434023407 1.9775940829036844 0.0010157664444444445 0.0001250295400000002 6.710846342953184 0.005526995070522294
12 0.000244140625 0.0012243422425228688 0.5056878986656352 0.06402549621018291 1.9933013494383838 0.0020201676200000004 0.00025105098888888875 10.761605178336456 0.11046523167423034
13 0.0001220703125 -0.00014921338690620714 0.5016980327849674 0.03374501698991283 1.996913754897589 0.0039882449533333334 0.0005025994594444442 17.928476680320593 0.18052876373810223
14 6.103515625e-05 0.00022689667583249127 0.5021285209653822 0.017131933691236143 2.0041262470674095 0.007934608511111111 0.0009998219561111114 35.026340465125415 0.009728133045069148
15 3.0517578125e-05 -5.953824477013307e-05 0.5030165425713956 0.008848502221610299 2.006407020332402 0.01583280204111111 0.002015708239444445 60.853404328808345 0.04579471914748419
16 1.52587890625e-05 8.300680235046975e-05 0.50402943877001 0.004430939164164866 2.0063305198339694 0.031396242214444446 0.003749269896666667 131.0840881064315 0.04535491335281044

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.010000000000000002 ***
*********************************************************
alpha = 0.34513214783243423 (exponent for weak convergence) 
beta = 0.8090016610589811 (exponent for variance of bias estimate) 
gamma = 0.9873124275739411 (exponent for cost of bias estimate) 

