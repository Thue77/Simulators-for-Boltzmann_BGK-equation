
*********************************************************
***Python ml_test for APS method on 22-May-2021 03:45:27         ***
***    Altered diffusive coefficient is used!!      ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[5.1] and eps = 0.032  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 180000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.49977453887310547 0.0 2.5353889546157946 0.0 6.647777777777562e-07 0.0 0.0
1 0.5 0.00035933272312063474 0.5053909914773521 0.7018180948894228 1.6745790924136665 9.170355555555194e-07 6.476344444444572e-07 12.375626249409517 0.1996376841068397
2 0.25 -7.910290957693751e-05 0.5011258429109846 0.46893386959930966 1.2303866546169078 9.492455555556173e-07 8.092972222221878e-07 10.92294070679531 0.1917042419797954
3 0.125 -0.0025675863406929267 0.4992004124635106 0.3422263455289573 0.9702682367002959 1.3636055555555199e-06 1.1072194444444566e-06 9.23323080366213 0.03389550123676183
4 0.0625 -0.00043553678465455285 0.4999340755655565 0.26118465425614146 0.8176657293041695 2.0749333333333828e-06 1.5906494444443413e-06 8.698875772992487 0.06888620787272073
5 0.03125 0.0011081513156437515 0.5007439890890768 0.20178923312708555 0.721636490637119 3.5627949999999704e-06 2.082552222222252e-06 8.238048676875891 0.019145777103809592
6 0.015625 0.0010381020617409814 0.5009986004491133 0.1533846338587041 0.6622163914627348 6.3706955555555485e-06 4.069314999999957e-06 8.270243486322016 0.053920968991502075
7 0.0078125 0.00038159320028791814 0.5000841906639708 0.11664279851969205 0.6262820864890207 1.0997473333333435e-05 7.727265000000038e-06 8.703237076271192 0.09415148199130875
8 0.00390625 0.0006511078638518123 0.5013332227663146 0.09253559915095233 0.6028121617529612 2.0346436666666613e-05 1.4848937777777691e-05 9.13429647329773 0.04517087376077178
9 0.001953125 0.0004693553678660688 0.49997593345513214 0.0832431438446111 0.5771886939187776 3.9991451666666616e-05 3.0085579444444436e-05 8.407624019511786 0.14157533319973623
10 0.0009765625 -0.0006206293319003074 0.5005940566670576 0.08704441141997588 0.5450232015823765 8.203395166666666e-05 6.095341944444451e-05 6.824990716048209 0.09770451563377804
11 0.00048828125 -0.0010063144921905155 0.49917371736903415 0.1023742538162158 0.5032671179426768 0.0001681671583333333 0.00012257849111111115 5.309181607526848 0.033124553383925996
12 0.000244140625 -0.0004145714154813977 0.4992422102437283 0.1143337981485176 0.44852583145799063 0.00034354083333333336 0.00024063433277777776 4.565287756576069 0.03978159322818651
13 0.0001220703125 -0.0009465413961221168 0.5007784199631033 0.11896163578493008 0.4046107775869078 0.0006789280744444443 0.0004756350344444446 4.545452825248464 0.2127036823455008
14 6.103515625e-05 -0.0007063743959622304 0.5022912479744603 0.11582549439771038 0.3747444186140315 0.0012878435699999998 0.0009478606805555557 5.124543177512308 0.19756105989218817
15 3.0517578125e-05 0.00029195073020052013 0.49668105525893874 0.10780240017149466 0.3638018330162126 0.0025027716666666667 0.0018889511772222217 6.003019164701213 0.5407221176340833
16 1.52587890625e-05 0.00033810787652091394 0.5005985736181208 0.10128956631918049 0.3539619552659195 0.004954877169444444 0.0037689269022222224 7.0025937251771 0.33382752866570503

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.001024 ***
*********************************************************
alpha = 0.5314747124591315 (exponent for weak convergence) 
beta = 0.09673363423360928 (exponent for variance of bias estimate) 
gamma = 0.9719459644409514 (exponent for cost of bias estimate) 

