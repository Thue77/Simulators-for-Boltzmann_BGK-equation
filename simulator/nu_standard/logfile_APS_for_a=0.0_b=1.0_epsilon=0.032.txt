
*********************************************************
***Python ml_test for APS method on 21-May-2021 23:02:45         ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[1.] and eps = 0.032  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 180000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.4997568012781083 0.0 2.028997307788586 0.0 5.431744444444399e-07 0.0 0.0
1 0.5 0.0001989476931900677 0.4973061070483568 0.5288316549506371 2.03726228524154 8.779538888889012e-07 6.313138888888404e-07 9.964326081091121 0.10469956356989474
2 0.25 -0.0016560623779491893 0.5019425998909121 0.6193482497529413 2.0313513865353445 9.217300000000329e-07 8.089388888888117e-07 6.4026455330550105 0.24450746279723587
3 0.125 -0.0020955858026528123 0.5000206498023844 0.6763852356692199 2.025592235033397 1.3150955555554431e-06 1.1061627777778366e-06 4.883498438322757 0.006689286687913566
4 0.0625 0.0021927959978922623 0.49683486589936776 0.6934691909547172 2.0275095432183927 2.1381722222222046e-06 1.5727444444443961e-06 3.9462818417161105 0.20670362275442467
5 0.03125 0.006461071438563298 0.4991353555131822 0.6997644153832343 2.004379013498032 3.633423888888861e-06 2.1738377777777393e-06 3.4648310362516592 0.16005583755421457
6 0.015625 -0.00037991355683629214 0.5042916893624846 0.6949395208553009 1.965410556270749 6.347253333333371e-06 4.100113333333352e-06 3.222355901908748 0.21442742091588152
7 0.0078125 -0.0025432998052846894 0.49792686140572234 0.6741530673220736 1.9307426484734937 1.1864059444444466e-05 7.82701722222221e-06 3.1364435433216276 0.14960389233016858
8 0.00390625 -0.0013863582341474912 0.4990456989959546 0.6442385094896907 1.8624355760254256 2.1097986111111074e-05 1.549637499999999e-05 3.0983581597452625 0.09960680997062196
9 0.001953125 0.00010240285907787584 0.4981801386307128 0.5878833915994631 1.7983990809779 4.334389555555554e-05 3.084979333333339e-05 3.051728838773589 0.039421469123781604
10 0.0009765625 -0.002203077084043634 0.49809051573505625 0.5162247039575483 1.7846760179215655 8.800299555555549e-05 6.33511494444444e-05 3.051596399157345 0.08802591791879616
11 0.00048828125 0.0014717736685638933 0.4980865209441854 0.41893131331667893 1.8084189548327276 0.000170207535 0.00012227123944444436 3.064751890907422 0.06271299659660731
12 0.000244140625 0.00042893196019709313 0.49711372549414323 0.30859970185135444 1.87728863482142 0.00032411404055555557 0.0002427250333333334 3.1034964865355352 0.060614031650011335
13 0.0001220703125 0.0018308427821985896 0.5031177148931916 0.20104938330734554 1.937074169175749 0.000624103018888889 0.0004802560366666667 3.249714996266286 0.18383616785806883
14 6.103515625e-05 0.001498577334710483 0.509141350036051 0.11734525558314055 1.9694522742437177 0.001260465981666667 0.000959360941111111 3.498369055507515 0.2039507869014712
15 3.0517578125e-05 -0.0003104682240502152 0.49993581864038683 0.06309535310844369 2.009927361393882 0.0025046240783333333 0.0019297393399999997 3.8492826336327886 0.4094524025680441
16 1.52587890625e-05 -2.2238045898033197e-05 0.495238307644423 0.03325647093635035 2.0186485657676685 0.005085744239444445 0.0038860267405555556 4.753912396191723 0.21887156004124633

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.001024 ***
*********************************************************
alpha = 0.9122781130119513 (exponent for weak convergence) 
beta = 0.7406347741389729 (exponent for variance of bias estimate) 
gamma = 0.9819892447730043 (exponent for cost of bias estimate) 

