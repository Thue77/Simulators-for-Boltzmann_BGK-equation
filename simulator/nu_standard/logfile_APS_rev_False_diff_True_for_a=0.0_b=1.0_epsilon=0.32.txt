
*********************************************************
***Python ml_test for APS method on 21-May-2021 22:16:35         ***
***    Altered diffusive coefficient is used!!      ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[1.] and eps = 0.32  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 180000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.5000312909443622 0.0 1.9197138120849537 0.0 7.164222222223139e-07 0.0 0.0
1 0.5 -0.0003100172017126426 0.5028942369655718 0.07223038593249273 1.8541761910968033 8.391250000000146e-07 6.377899999999591e-07 2.867760992394655 0.1487826102053454
2 0.25 -0.0013132203586056965 0.5000888484845428 0.1231963254561139 1.7649956668389146 9.432011111111175e-07 8.082616666666887e-07 3.7987530839063237 0.06938840424029094
3 0.125 -0.00036045577913406437 0.49878824917333414 0.18501753007808497 1.6946125992840035 1.3856866666666277e-06 1.1342350000000006e-06 4.909544460205877 0.04344353560395778
4 0.0625 -0.0004902083299008099 0.500869178041701 0.22748900407140932 1.6736284775507801 2.1830655555555486e-06 1.387831666666628e-06 7.16381833925038 0.11834770064519284
5 0.03125 1.7875152685211522e-06 0.5039465138211848 0.2202117899003344 1.6954449788613302 3.7264894444444645e-06 2.2767855555555073e-06 10.890235765467821 0.1419058494191408
6 0.015625 -0.0011102019730878424 0.4983496405724378 0.1699720756546735 1.7322881061741224 6.3782077777777684e-06 3.899311666666666e-06 19.148131230333977 0.2093727581867889
7 0.0078125 -0.0006117241109282044 0.5053951193368367 0.10968513444152629 1.7721082956665275 1.0826238888888894e-05 7.670918888888857e-06 32.377518326029154 0.3635626046949776
8 0.00390625 0.0002007730610890751 0.4957595567562647 0.06461008255337403 1.8116232818585816 1.981232333333326e-05 1.5166814444444496e-05 70.27245665473639 0.47454754657447906
9 0.001953125 0.0005655842313599573 0.4992682551000456 0.03363149335783545 1.8245681472165376 3.824677166666663e-05 2.9205176111111167e-05 131.61572455475465 0.14451451869515164
10 0.0009765625 0.0001603303571980725 0.5051838513586598 0.01768048648293547 1.8263171250433392 7.476259500000002e-05 5.7944949444444424e-05 224.49463755941912 0.2870812613824569
11 0.00048828125 0.0003628072749307844 0.5016867934919772 0.008810621235570934 1.8420849265817387 0.00015071302888888883 0.00011632951666666662 446.5691705051856 0.1947778713134967
12 0.000244140625 -0.00012802064614313713 0.5076422209103927 0.004732095311664613 1.8160904997492529 0.0003027647483333332 0.0002316573088888892 1471.7510909163263 0.31017970136280154
13 0.0001220703125 9.244398613631467e-05 0.5059374253614257 0.002244391015382655 1.81694822082641 0.0006036315816666666 0.0004691273683333334 1684.9464327258681 0.09266259469782177
14 6.103515625e-05 3.03930600489688e-05 0.49914221869617936 0.0011600899932453091 1.825096998620756 0.0012060988344444444 0.0009377272949999998 2531.052564935622 0.35320100589550907
15 3.0517578125e-05 -1.5706351394872698e-05 0.5012766321069768 0.0004799434771408088 1.8327771453647097 0.0024048682666666663 0.001875052487777778 3322.0240597457982 0.1115180199338658
16 1.52587890625e-05 1.806575172658425e-05 0.5018555784185958 0.00043708331200675285 1.8270278891250196 0.004795614847777778 0.0037655594122222224 23032.76685964655 0.02909366554219667

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.1024 ***
*********************************************************
alpha = 0.20889660019855946 (exponent for weak convergence) 
beta = 0.8903103472556995 (exponent for variance of bias estimate) 
gamma = 0.954067503819648 (exponent for cost of bias estimate) 

