
*********************************************************
***Python ml_test for APS method on 21-May-2021 14:48:03         ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[1.] and eps = 0.32  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 120000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 1.000232465168055 0.0 0.19286108455597062 0.0 2.902158333334034e-07 0.0 0.0
1 0.5 0.00015891777803134447 0.9999692112290024 0.06046429636627354 0.18625029792418224 5.290974999999421e-07 2.1679916666676274e-07 10.514733052524669 0.04365685561453044
2 0.25 -1.2126478428226464e-05 1.000785397042047 0.0559572695176257 0.17814927498629252 5.280166666666493e-07 4.061141666666046e-07 7.690748330114596 0.0877320546366651
3 0.125 -0.0006852014113151097 0.9990319491997554 0.05008073482268308 0.17051784302388684 9.525058333332836e-07 7.244133333333143e-07 6.536538062804488 0.11649996633770389
4 0.0625 0.0006056076926061495 1.001488855520716 0.041054599503244915 0.16780747450175793 1.8099283333333697e-06 1.3634366666667102e-06 7.570273441493417 0.20851487026518048
5 0.03125 0.0004376793031555664 0.9970459743903919 0.031129648961905506 0.17022177997042454 3.3888491666666928e-06 1.9202791666666976e-06 10.186254721418031 0.5643156101133104
6 0.015625 -0.0007758898322403406 0.9999595979888161 0.020395811880740435 0.17474837094146012 6.454924166666724e-06 3.7713166666667537e-06 18.58037566931727 0.4376602382461493
7 0.0078125 0.0001219424617223586 1.0011968362382389 0.011894619323438273 0.17818787062021713 1.1492881666666635e-05 7.719115000000088e-06 29.01945379361218 0.1356734891418247
8 0.00390625 -0.0002993920117806334 1.0011312797560235 0.006747161440109207 0.17912954779546508 2.1124147500000017e-05 1.5243754999999837e-05 60.3032338325412 0.02911155560333227
9 0.001953125 -9.005887823693944e-06 0.9999481021721278 0.0036911699213626075 0.18255881762803805 3.964425999999997e-05 3.0045819166666555e-05 138.214084550424 0.14878467042487378
10 0.0009765625 0.00011688865530803225 0.9979428536583238 0.0018583281381271376 0.18403548249249146 7.705902666666666e-05 6.0891118333333336e-05 254.20026511449612 0.27246076913010014
11 0.00048828125 0.00010490259061712096 1.0000392547287298 0.0009672464469774344 0.18311020653836518 0.0001532844508333334 0.0001239137 790.2790469794663 0.2589598882116536
12 0.000244140625 9.521683179873749e-06 0.9999909685420592 0.0005975914856305716 0.1841727546034011 0.00030786381833333335 0.0002404241783333333 3447.9404020040624 0.007572296535396685
13 0.0001220703125 5.037217926018456e-05 1.0004200656011997 0.00023701688619462972 0.18233739464171572 0.0006095161158333333 0.00047570537333333336 1860.1763262048137 0.050176059870817954
14 6.103515625e-05 -5.379676088923907e-06 1.000240273933512 0.00012000582637040693 0.18339454174078162 0.0012182723258333335 0.0009485721341666666 4180.026490518408 0.023249964697314468
15 3.0517578125e-05 2.3706487501419874e-05 1.0019047661333653 6.86856603585039e-05 0.18447168595511254 0.0024003571433333336 0.001911742035 6471.971555918133 0.21876894299508054
16 1.52587890625e-05 1.111694082109515e-05 0.9971842846963483 2.7662995205277932e-05 0.18340110963116785 0.0048295751883333325 0.0038850136124999996 7377.831871491013 0.6330805969631765

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.1024 ***
*********************************************************
alpha = 0.5170329873655878 (exponent for weak convergence) 
beta = 0.9259434381594973 (exponent for variance of bias estimate) 
gamma = 0.955615730781525 (exponent for cost of bias estimate) 

