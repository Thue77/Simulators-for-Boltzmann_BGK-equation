
*********************************************************
***Python ml_test for APS method on 17-May-2021 17:07:12         ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[10.] and eps = 0.5  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 120000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.5000720084375385 0.0 0.6202907592415128 0.0 7.247741666666012e-07 0.0 0.0
1 0.5 0.0006385650668516346 0.4995887154433696 0.13892181889172656 0.4321092892278022 9.315625000000457e-07 6.627808333334428e-07 7.74025148518604 0.07126809705313636
2 0.25 0.000670587609928063 0.49950837837246453 0.10505567020959174 0.3272500887956442 8.934141666665952e-07 7.980616666666052e-07 6.496133667861811 0.05581434758403272
3 0.125 -0.000504868491563511 0.5005276030468901 0.08231380398650123 0.2710030013536354 1.2723375000000203e-06 1.125486666666653e-06 5.012755583839951 0.12756932207635088
4 0.0625 0.00037734778248472837 0.5010698376936202 0.06896502200391953 0.2412231305295584 2.0920016666667724e-06 1.8170158333333575e-06 4.304319517647055 0.014940716772022383
5 0.03125 0.00016043749963365222 0.4983238541454572 0.058750146859279984 0.22468424847183516 3.927296666666654e-06 2.3188791666666356e-06 4.070732996429459 0.27792473210428
6 0.015625 0.0005745975834781403 0.4991558616200305 0.047346371067633744 0.22039927212863597 7.346401666666698e-06 4.360675833333379e-06 4.379029092470824 0.025599823589131522
7 0.0078125 -0.0005611640175450187 0.5000385812623359 0.03560870080057308 0.22358269970506828 1.24924141666666e-05 8.002840000000097e-06 5.121592394079282 0.14741212313629096
8 0.00390625 8.356490388764506e-05 0.5022044437548184 0.023874184062741718 0.2263357296333598 2.175184666666657e-05 1.5902825833333387e-05 7.080814840068428 0.21796917186549153
9 0.001953125 -0.00033553858404567383 0.49873405717978414 0.014326625109498805 0.22981979806649572 4.104130416666679e-05 3.1176286666666426e-05 11.055239843481703 0.33677774124886284
10 0.0009765625 1.7293220382585325e-05 0.4992086086676736 0.008011958872182172 0.23487720703841236 7.851026916666661e-05 6.111285583333335e-05 19.02406593428011 0.05011611400401368
11 0.00048828125 -0.00022472598261817146 0.4986892555641925 0.0041869821630621 0.23583679583851944 0.00015443681083333343 0.00012136511500000004 36.91756341021806 0.03287083630455839
12 0.000244140625 -4.016399685898642e-06 0.5020525614835903 0.0021106814198925436 0.23648029802893705 0.00030266075916666666 0.0002424688266666667 56.79346125252793 0.3820005037704047
13 0.0001220703125 -6.849951685538702e-05 0.5001207323558939 0.0011050795071131287 0.23827221487562117 0.0006004816866666666 0.00048331252333333376 114.69904927767233 0.21352180854649536
14 6.103515625e-05 -0.00011872129823745593 0.50022148078701 0.0005777832630774956 0.23691034604243688 0.0012029615216666665 0.0009731553233333329 247.52241902516957 0.025370016388141917
15 3.0517578125e-05 -8.682408174685094e-06 0.49931537305539014 0.00028053796158467444 0.23579746127421713 0.0024021715108333334 0.0019390123758333334 562.2356455310771 0.10477053147177114
16 1.52587890625e-05 -5.251351519917633e-06 0.501462082456338 0.0001372024563358041 0.23648014921153693 0.004768067224166667 0.0038761526066666665 655.7995342985702 0.25263134013677274

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.25 ***
*********************************************************
alpha = 0.5507053173006898 (exponent for weak convergence) 
beta = 0.9077463498696785 (exponent for variance of bias estimate) 
gamma = 0.9626564534916263 (exponent for cost of bias estimate) 

*********************************************************
*** MLMC complexity test ***
*********************************************************
 e2 value mlmc_cost N_l dt 
---------------------------------------------------------
 0.01 0.639971030722029 0.8990162999997438 [272  72  56  72  40  40  40] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125
 0.00039063] 
 0.005 0.5487105100294234 0.5057225000001608 [952 136  72  56  40  40] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125] 
 0.0025 0.5746480318809197 0.751599700000213 [3136  312  136   72   88   40] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125] 
 0.00125 0.4889653384024722 1.508392099999412 [6712  792  360  160   72   56   40] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125
 0.00039063] 
 0.000625 0.5232188843564266 4.808193000000301 [20760  3248  1544   600   240    88    56    40    40] [2.500000e-02 1.250000e-02 6.250000e-03 3.125000e-03 1.562500e-03
 7.812500e-04 3.906250e-04 1.953125e-04 9.765625e-05] 
 0.0003125 0.48711544099161425 27.54457389999959 [56208 10112  4784  2248   616   320   152    40    40    40    40    40] [2.50000000e-02 1.25000000e-02 6.25000000e-03 3.12500000e-03
 1.56250000e-03 7.81250000e-04 3.90625000e-04 1.95312500e-04
 9.76562500e-05 4.88281250e-05 2.44140625e-05 1.22070313e-05] 
 0.00015625 0.49695726320317724 0.45760909999933125 [16592  3616  1696   752] [0.025    0.0125   0.00625  0.003125] 
 7.8125e-05 0.501573743768824 0.40401710000003277 [29096  6456  3624  2448] [0.025    0.0125   0.00625  0.003125] 
 3.90625e-05 0.5061818348141194 45.91570309999918 [306616  85912  52600  28304  11112   4184   1600    488    232     56
     40     40] [2.50000000e-02 1.25000000e-02 6.25000000e-03 3.12500000e-03
 1.56250000e-03 7.81250000e-04 3.90625000e-04 1.95312500e-04
 9.76562500e-05 4.88281250e-05 2.44140625e-05 1.22070313e-05] 
 1.953125e-05 0.49466733530389617 18.888976900000273 [336512  95752  58456  34168  16384   8016   2144    632    152] [2.500000e-02 1.250000e-02 6.250000e-03 3.125000e-03 1.562500e-03
 7.812500e-04 3.906250e-04 1.953125e-04 9.765625e-05] 
 9.765625e-06 0.4983084915990348 5.9452787000002445 [390808 110168  66176  39000  11344] [0.025     0.0125    0.00625   0.003125  0.0015625] 
 4.8828125e-06 0.4999078524634949 35.360979799999484 [1473456  408528  255256  148672   79560   41840   18288    4392] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125
 0.00039063 0.00019531] 
 2.44140625e-06 0.499431676558603 7.289458200000183 [637032 173224 111016  65344] [0.025    0.0125   0.00625  0.003125] 

