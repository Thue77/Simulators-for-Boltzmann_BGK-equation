
*********************************************************
***Python ml_test for APS method on 19-May-2021 10:36:24         ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[10.] and eps = 0.1  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 120000 samples and 21 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.5022774503448105 0.0 0.630882477781497 0.0 1.400981874515613e-06 0.0 0.0
1 0.5 0.0014442239911995297 0.498396491333548 0.1440634039226743 0.43133078756741944 2.7843637376402814e-05 1.2146296290059885e-06 7.651382796866128 0.3359011239751025
2 0.25 0.0007188280329263816 0.5003591066365782 0.10860761374340239 0.333969284835446 1.8061187583953141e-06 1.5147550341983637e-06 5.958608844050336 0.09181612600357407
3 0.125 5.043357992265559e-05 0.4989897544762319 0.09051676578056563 0.2824925338460914 2.5865109171718357e-06 1.8775029573589563e-06 4.645853289022635 0.11624991971492811
4 0.0625 0.0007500731549678023 0.49910858831466265 0.08154859807435574 0.25363405439474973 3.696401308601101e-06 3.1045814665655294e-06 3.9893398522842243 0.05519033859454876
5 0.03125 -0.0010898719456251707 0.5034588944890979 0.07590114946685013 0.2434294791337286 6.65603761250774e-06 5.225381255149841e-06 3.485549907448458 0.4936530923768155
6 0.015625 0.0007466421229457026 0.5007137070960688 0.07259387489199559 0.23382612196524172 1.218210671407481e-05 8.414386973405877e-06 3.243848394355051 0.32349981677283224
7 0.0078125 -4.351661731099761e-06 0.5009129393259772 0.06889077809387292 0.22568794711277224 2.2060133858273426e-05 1.8063109461218118e-05 3.1585925060636137 0.01925148431123327
8 0.00390625 0.0018467934699362388 0.5023220156140121 0.06472121748786266 0.21770821406864432 4.173988049539427e-05 3.527762146356205e-05 3.0535161939690774 0.042258031028340276
9 0.001953125 -0.00021868725966971663 0.5004416622726955 0.059685656817096415 0.21180747268844113 8.64909616454194e-05 6.524509200826287e-05 3.011557001344499 0.16383633224337227
10 0.0009765625 -0.00012141090738655366 0.49871608209724205 0.051778965979859315 0.2080903475106473 0.00017727371954048674 0.00013957482726934054 3.0579816401638595 0.16192524861624102
11 0.00048828125 -0.00014638977138422928 0.5011025392154079 0.042817563294686854 0.21016474011819447 0.00032853413779909414 0.00025840826941033205 3.072265496886834 0.26077574868494185
12 0.000244140625 -0.0003419773875356556 0.5007902089404883 0.03141358644428978 0.2174721164319096 0.0006416475110842535 0.000510648388384531 3.1042837501701213 0.0031064489252771847
13 0.0001220703125 0.0009114968715190261 0.49881081502261526 0.020482384573501156 0.2225559166923849 0.0012471578075240056 0.0009441851708572357 3.278737966353999 0.3087374890493724
14 6.103515625e-05 -0.00026557011083158585 0.5006400005750938 0.011943821100929347 0.22631178249218464 0.0023620846721033257 0.0016848315414196501 3.4058842697621547 0.22888792626799087
15 3.0517578125e-05 -4.044757686021328e-05 0.500154542029732 0.006520872010264887 0.22941929464470623 0.004212506641369934 0.004403537496241431 3.8622470771533792 0.04962611345172346
16 1.52587890625e-05 -2.5534183649098465e-06 0.49838061076065243 0.00341453104155393 0.2325541351161446 0.010659379759073878 0.007382454028554882 4.728825158862835 0.20059931886223695
17 7.62939453125e-06 -6.448931963714116e-05 0.49997327584777956 0.0017395313374774693 0.23282783475201305 0.020372937698413928 0.01721384956437784 6.387399071242206 0.1901218622247446
18 3.814697265625e-06 8.606748964656204e-05 0.5016275883759188 0.000867772740930714 0.2317411025259548 0.04035260158491631 0.032074572930065916 10.261806205010028 0.1822929744633712
19 1.9073486328125e-06 4.699714953238527e-05 0.5018307879892717 0.0004449158597828691 0.2327846432604157 0.08007473863551083 0.06670613264332836 16.26137508383743 0.018312017234435898
20 9.5367431640625e-07 -8.253203195885624e-05 0.5001534739501432 0.00022797518966638101 0.23375420574211725 0.16158260636421232 0.1327732276823527 34.38767108424328 0.18770511277056698

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.010000000000000002 ***
*********************************************************
alpha = 0.3310230845729082 (exponent for weak convergence) 
beta = 0.8669521028273257 (exponent for variance of bias estimate) 
gamma = 0.9997984163002822 (exponent for cost of bias estimate) 

*********************************************************
*** MLMC complexity test ***
*********************************************************
 e2 value mlmc_cost N_l dt 
---------------------------------------------------------
 0.01 0.45072223627634456 115.90239505469799 [1032   96   64   32   16   16   16   16] [1.0000e-03 5.0000e-04 2.5000e-04 1.2500e-04 6.2500e-05 3.1250e-05
 1.5625e-05 7.8125e-06] 
 0.005 0.5191316837179714 10.97464812360704 [1096  112   72   32] [0.001    0.0005   0.00025  0.000125] 
 0.0025 0.5394915395912707 948.8456965126097 [12168   816   384   184    80    48    32    16    16    16    16] [1.000000e-03 5.000000e-04 2.500000e-04 1.250000e-04 6.250000e-05
 3.125000e-05 1.562500e-05 7.812500e-06 3.906250e-06 1.953125e-06
 9.765625e-07] 
 0.00125 0.49721219071324646 11.690852649509907 [3288  544  216  120] [0.001    0.0005   0.00025  0.000125] 
 0.000625 0.49220661599970533 4826.15733532235 [81448 12736  4760  1976   672   312   152    48    32    16    32    16
    16] [1.00000000e-03 5.00000000e-04 2.50000000e-04 1.25000000e-04
 6.25000000e-05 3.12500000e-05 1.56250000e-05 7.81250000e-06
 3.90625000e-06 1.95312500e-06 9.76562500e-07 4.88281250e-07
 2.44140625e-07] 
 0.0003125 0.4796447779030561 2838.474292675033 [105400  20120   9800   3328   1120    336    144     64     32     32
     16     16] [1.0000000e-03 5.0000000e-04 2.5000000e-04 1.2500000e-04 6.2500000e-05
 3.1250000e-05 1.5625000e-05 7.8125000e-06 3.9062500e-06 1.9531250e-06
 9.7656250e-07 4.8828125e-07] 
 0.00015625 0.4993733702985201 129.0588510222733 [73992 15272  7400  3504   592   232] [1.000e-03 5.000e-04 2.500e-04 1.250e-04 6.250e-05 3.125e-05] 
 7.8125e-05 0.5041820933819429 726.2076922189444 [221288  60296  35408  18856   5840   2000   1024    216    120] [1.00000e-03 5.00000e-04 2.50000e-04 1.25000e-04 6.25000e-05 3.12500e-05
 1.56250e-05 7.81250e-06 3.90625e-06] 
 3.90625e-05 0.4990708097836016 3906.852615194396 [617320 167680  96040  53120  24464   9832   2864    744    288     88
     88] [1.000000e-03 5.000000e-04 2.500000e-04 1.250000e-04 6.250000e-05
 3.125000e-05 1.562500e-05 7.812500e-06 3.906250e-06 1.953125e-06
 9.765625e-07] 
 1.953125e-05 0.5010153740275872 196.39610137231648 [354384  99152  54056  28800   4056] [1.00e-03 5.00e-04 2.50e-04 1.25e-04 6.25e-05] 
 9.765625e-06 0.5007531601300765 1236.6874744948 [1070152  301616  174824  101544   53432   24272    8176    1344] [1.0000e-03 5.0000e-04 2.5000e-04 1.2500e-04 6.2500e-05 3.1250e-05
 1.5625e-05 7.8125e-06] 
 4.8828125e-06 0.49931435829348697 716.1750928945839 [1710320  458504  273728  152960   20776] [1.00e-03 5.00e-04 2.50e-04 1.25e-04 6.25e-05] 
 2.44140625e-06 0.5010476710120662 2543.3074720781296 [2907960  799472  489568  283488  147568   72704   15928] [1.0000e-03 5.0000e-04 2.5000e-04 1.2500e-04 6.2500e-05 3.1250e-05
 1.5625e-05] 

