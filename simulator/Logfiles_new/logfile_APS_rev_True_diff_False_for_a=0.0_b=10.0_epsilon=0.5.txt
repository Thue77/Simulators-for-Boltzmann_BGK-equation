
*********************************************************
***Python ml_test for APS method on 17-May-2021 19:38:01         ***
***    Reverse splitting is used!!      ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[10.] and eps = 0.5  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 120000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.49930616944637446 0.0 0.23976692265642624 0.0 7.205233333333302e-07 0.0 0.0
1 0.5 0.0008252719150996231 0.5002006560064961 0.07932580431359207 0.23644868135299196 2.045504166666786e-06 5.989300000000124e-07 8.422049767959788 0.006355296162310248
2 0.25 -0.0012678636266842546 0.499469732404789 0.07625925272047368 0.23498344197566656 2.569235833333394e-06 8.007033333333524e-07 6.598170324616505 0.04971328073483768
3 0.125 -0.0011126440686589653 0.4984146491993023 0.07081945997136548 0.2276318843487498 4.471090000000129e-06 1.0804375000001088e-06 4.741552241817207 0.0054126018334852265
4 0.0625 0.0016552448492798048 0.5000417712187121 0.06521241341636057 0.21740098891080617 8.455791666666693e-06 1.698678333333466e-06 4.196568418506828 0.0027089698707114655
5 0.03125 0.0006430290984394906 0.4986120664987119 0.05959657400946459 0.21564185938152952 1.6991254166666653e-05 3.320014999999958e-06 4.058233710885395 0.20373421122686375
6 0.015625 -0.0004552213017846956 0.5006724438717562 0.05326302335531646 0.21595793129636437 3.296888416666667e-05 5.410132500000072e-06 4.190175572098407 0.25043800941911526
7 0.0078125 0.0010226011601081352 0.4989373570311128 0.04266219934958993 0.220449993052174 6.316197499999993e-05 1.002526416666664e-05 4.618259772923174 0.27913340511543067
8 0.00390625 0.00042154354156020025 0.5002479770739335 0.029564196939925673 0.22582826721918453 0.000124965605 1.8698811666666634e-05 6.042599009223242 0.09193498015726029
9 0.001953125 0.00011739081517592162 0.5011400419380356 0.01778668738140679 0.22972763972940763 0.0002472159858333333 3.38829916666666e-05 8.531349527069231 0.08222568022911711
10 0.0009765625 -7.200399397339382e-05 0.5006311411793564 0.00986124369588812 0.2348913525543817 0.0004799700058333333 6.665479666666675e-05 13.90993297631984 0.04744704865629771
11 0.00048828125 0.0001032738227120768 0.49689852644835003 0.0053500486748608205 0.23480829827759847 0.0009596238608333334 0.00013779776916666625 28.719978085731633 0.42492607271972754
12 0.000244140625 -8.238949761238038e-05 0.4990785350464694 0.002741366009928743 0.23834747010080673 0.0019253726866666665 0.0002688585549999997 50.84700152957514 0.254833554056866
13 0.0001220703125 -2.5495413706053853e-05 0.4975206715620148 0.0013766744425810946 0.23805476083228866 0.003830274298333334 0.0004909905241666673 93.88767073835565 0.17463386775122397
14 6.103515625e-05 -1.4921228055201004e-05 0.5029220700021465 0.0007381663809174093 0.23647710005440858 0.007591494814166666 0.0009693474499999989 193.20912531742528 0.6245690084446378
15 3.0517578125e-05 -1.1664434295923453e-05 0.49956825038164626 0.00032606118415619316 0.2378623395363854 0.015318728005833334 0.0019797175141666656 266.0588306279953 0.38900849882429145
16 1.52587890625e-05 1.3260425748497065e-05 0.4969705613987555 0.0001528426149835562 0.23761228612107688 0.03041531164333333 0.003793078596666664 383.6207769102861 0.3052937294384822

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.25 ***
*********************************************************
alpha = 0.6808974205795241 (exponent for weak convergence) 
beta = 0.9156412411948504 (exponent for variance of bias estimate) 
gamma = 0.9906889405853231 (exponent for cost of bias estimate) 

*********************************************************
*** MLMC complexity test ***
*********************************************************
 e2 value mlmc_cost N_l dt 
---------------------------------------------------------
 0.01 0.509901893031528 6.487146700000039 [2920   72   48   32   16   16] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125] 
 0.005 0.5086111399859077 2.5001177000003736 [5216   88   48   32] [0.025    0.0125   0.00625  0.003125] 
 0.0025 0.4567837417124345 6.528703400000723 [15456   272   152    88    40] [0.025     0.0125    0.00625   0.003125  0.0015625] 
 0.00125 0.5068819608338221 3.125006099999837 [13624   312   232   136] [0.025    0.0125   0.00625  0.003125] 
 0.000625 0.48650181366966677 16.929398499997433 [73920  2544  1320   520   120   112] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125] 
 0.0003125 0.5043492768927973 2.5156780000002072 [26088  1976   936   440] [0.025    0.0125   0.00625  0.003125] 
 0.00015625 0.497629220706413 5.301552099999753 [58920  3736  1888   704] [0.025    0.0125   0.00625  0.003125] 
 7.8125e-05 0.502506842357668 4.878283700000338 [80008  6704  3176  1800] [0.025    0.0125   0.00625  0.003125] 
 3.90625e-05 0.49753474405083403 4.887985900000331 [143768  11280   6736   4432] [0.025    0.0125   0.00625  0.003125] 
 1.953125e-05 0.49951527884880664 7.666896099999577 [272048  24160  13736   6944] [0.025    0.0125   0.00625  0.003125] 
 9.765625e-06 0.5014576543151362 11.18103770000107 [573256  46008  28208  14240] [0.025    0.0125   0.00625  0.003125] 
 4.8828125e-06 0.498673438139548 173.51232049999976 [4043008  649168  414552  247416  105456   12552] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125] 
 2.44140625e-06 0.5000029797798251 38.15127969999935 [1742816  187064  131320   63080] [0.025    0.0125   0.00625  0.003125] 

