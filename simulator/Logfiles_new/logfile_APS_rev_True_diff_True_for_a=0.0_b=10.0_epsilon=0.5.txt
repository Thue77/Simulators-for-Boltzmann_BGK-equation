
*********************************************************
***Python ml_test for APS method on 17-May-2021 20:03:22         ***
***    Reverse splitting is used!!      ***
***    Altered diffusive coefficient is used!!      ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[10.] and eps = 0.5  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 120000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.4998882036046684 0.0 0.22914986305946922 0.0 5.627349999999846e-07 0.0 0.0
1 0.5 -4.348745832110068e-05 0.5004603182529489 0.0009264785896501819 0.22790780910804576 2.184635000000057e-06 5.754325000000431e-07 12.683149424476294 0.07205410345609793
2 0.25 -3.620853625083686e-05 0.5007919032235714 0.0022423524677402523 0.225486181824956 2.7240499999999557e-06 7.495733333333495e-07 8.172203608350356 0.042485949992889564
3 0.125 -0.000186808097080829 0.5000297819866966 0.005299233569123355 0.21849443534486596 4.406303333333324e-06 1.0843499999999414e-06 5.412226925134275 0.06544430537609468
4 0.0625 0.00022301788924579868 0.4984399100697983 0.011690894692982241 0.21161274949495792 8.791165000000116e-06 1.6733358333334299e-06 4.4984483895969065 0.2021437878832255
5 0.03125 -0.0004233465731677745 0.5014098914269423 0.02169071905621937 0.20947204577325773 1.638364500000004e-05 2.9371274999999623e-06 4.150460857208112 0.36792281520730735
6 0.015625 0.0011926649523515977 0.5007499005302571 0.030904738380975894 0.21105688076768342 3.27513999999999e-05 5.394283333333346e-06 4.357328039131704 0.19574402488797332
7 0.0078125 -0.00010220011436555424 0.501028676357612 0.03194940474168643 0.21794623008210195 6.325870583333337e-05 1.0116541666666616e-05 5.0990403630639225 0.03981112977015226
8 0.00390625 0.0003365200166545272 0.5012476343195367 0.02546437717419703 0.2243909673227285 0.000126515905 1.833575249999999e-05 6.53331680713058 0.012339447048634
9 0.001953125 0.0005711607415995779 0.499556548958154 0.016782134572608652 0.22954164401238106 0.00025026919249999995 3.858580749999998e-05 10.172573628702196 0.24134673683604585
10 0.0009765625 0.0005781531814712012 0.5036740003092774 0.009454184763548557 0.23305392085118753 0.0004957558233333333 7.312853916666656e-05 15.130968862633448 0.38587967534492246
11 0.00048828125 -0.0004784539100612667 0.5013212408278509 0.005130901726104569 0.23510589229563378 0.0010004624616666664 0.0001454548450000002 23.82815663178144 0.20824944017865657
12 0.000244140625 0.00017284976131087967 0.49849369679467614 0.0027271998792718424 0.23734703411236216 0.0019511418691666668 0.0002512821308333332 51.95706781737435 0.33824225045440615
13 0.0001220703125 0.0001621640606301002 0.5012022202943632 0.0013522190693820097 0.23800096940707166 0.0038302762049999997 0.0005070508575000005 121.54120671267428 0.2905966883437799
14 6.103515625e-05 -0.00010639878967805365 0.504098761504875 0.0006645755217616489 0.2378176166448855 0.007626235889166667 0.0009740194349999996 161.77274706833094 0.34630005296066146
15 3.0517578125e-05 -2.406227583488832e-05 0.4989254649934463 0.0003555289166738383 0.23999907135369283 0.015188783773333334 0.001990038823333332 287.6029365514434 0.5967198338684473
16 1.52587890625e-05 -2.9973744531306394e-05 0.49837981360493705 0.0001744313718902341 0.23785614090232365 0.03036228376083333 0.0037336326850000013 1476.9752650187827 0.06009766971847196

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.25 ***
*********************************************************
alpha = 0.37369994639657644 (exponent for weak convergence) 
beta = 0.8691507280062992 (exponent for variance of bias estimate) 
gamma = 0.9877211890128534 (exponent for cost of bias estimate) 

*********************************************************
*** MLMC complexity test ***
*********************************************************
 e2 value mlmc_cost N_l dt 
---------------------------------------------------------
 0.01 0.5011369262917021 37.6229802000023 [2264   88   48   32   16   16   16   16   16] [2.500000e-02 1.250000e-02 6.250000e-03 3.125000e-03 1.562500e-03
 7.812500e-04 3.906250e-04 1.953125e-04 9.765625e-05] 
 0.005 0.5015704153866705 3.6467415000006445 [5392  104   48   32   16] [0.025     0.0125    0.00625   0.003125  0.0015625] 
 0.0025 0.5467561768944567 168.71380250000198 [37792   528   344   200    96    80    16    32    16    16    16] [2.50000000e-02 1.25000000e-02 6.25000000e-03 3.12500000e-03
 1.56250000e-03 7.81250000e-04 3.90625000e-04 1.95312500e-04
 9.76562500e-05 4.88281250e-05 2.44140625e-05] 
 0.00125 0.5212591673279872 108.9580578999969 [64728  1528   680   464   136    64    72    16    16    16] [2.5000000e-02 1.2500000e-02 6.2500000e-03 3.1250000e-03 1.5625000e-03
 7.8125000e-04 3.9062500e-04 1.9531250e-04 9.7656250e-05 4.8828125e-05] 
 0.000625 0.48408189379434124 125.65435660000117 [109616   2688   1456    824    280    144     48     32     16     16] [2.5000000e-02 1.2500000e-02 6.2500000e-03 3.1250000e-03 1.5625000e-03
 7.8125000e-04 3.9062500e-04 1.9531250e-04 9.7656250e-05 4.8828125e-05] 
 0.0003125 0.4972323611542993 14.985245400000167 [104944   4792   3648   1608    384    136] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125] 
 0.00015625 0.4975171732000387 1343.624627500001 [524504  37384  20120   8816   3640   1448    496    128     96     40
     16     16     16     16] [2.50000000e-02 1.25000000e-02 6.25000000e-03 3.12500000e-03
 1.56250000e-03 7.81250000e-04 3.90625000e-04 1.95312500e-04
 9.76562500e-05 4.88281250e-05 2.44140625e-05 1.22070313e-05
 6.10351563e-06 3.05175781e-06] 
 7.8125e-05 0.48888412071111303 9472.222140999995 [1482176  137336   89216   45536   19256    5992    1608     904     288
      48      32      16      16      16      16      16      16] [2.50000000e-02 1.25000000e-02 6.25000000e-03 3.12500000e-03
 1.56250000e-03 7.81250000e-04 3.90625000e-04 1.95312500e-04
 9.76562500e-05 4.88281250e-05 2.44140625e-05 1.22070313e-05
 6.10351563e-06 3.05175781e-06 1.52587891e-06 7.62939453e-07
 3.81469727e-07] 
 3.90625e-05 0.5016199988233047 363.7799058999999 [1222432  118008   72848   40336   19032    7464    2248     480      72
      96      16] [2.50000000e-02 1.25000000e-02 6.25000000e-03 3.12500000e-03
 1.56250000e-03 7.81250000e-04 3.90625000e-04 1.95312500e-04
 9.76562500e-05 4.88281250e-05 2.44140625e-05] 
 1.953125e-05 0.5010631969320923 68.71001629999955 [1181176  125992   85576   49736   20408    6200    1544] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125
 0.00039063] 
 9.765625e-06 0.5014222615569693 73.47577189999856 [2138352  233920  158040   95920   33680    5424] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125] 
 4.8828125e-06 0.5009012572461471 151.49802210000234 [3969696  497728  357928  210688   98024   10864] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125] 
 2.44140625e-06 0.49993172780733713 679.5463200000045 [10630768  1396192   993288   618224   345464   175856    71392     8896] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125
 0.00039063 0.00019531] 

