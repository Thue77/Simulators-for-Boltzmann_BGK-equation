
*********************************************************
***Python ml_test for APS method on 17-May-2021 22:35:37         ***
***    Reverse splitting is used!!      ***
***    Altered diffusive coefficient is used!!      ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[10.] and eps = 0.03  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 120000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.49876960091361744 0.0 0.23251524879315705 0.0 6.60633333333216e-07 0.0 0.0
1 0.5 1.0831460774152838e-06 0.4987144659980548 1.5620558220327157e-06 0.23195250858203514 2.081825833333362e-06 6.636250000000269e-07 3.313183079306366 0.006726508978125076
2 0.25 -1.4664531436676202e-06 0.5003120957543965 3.108330645449105e-06 0.23368782677678318 2.8660199999999728e-06 7.620516666666077e-07 3.1187761786363764 0.19099047812068332
3 0.125 -9.297684151995738e-07 0.5004084666463438 6.289862974055328e-06 0.23329840024338144 4.7981866666667375e-06 1.049274999999857e-06 3.148592005780033 0.011595582857750112
4 0.0625 -7.881063771104397e-06 0.4998506616821126 1.2749532467957417e-05 0.23299515018364275 8.862435833333334e-06 1.6275666666665837e-06 3.0911343747000295 0.0655125437911557
5 0.03125 1.4483240114327726e-05 0.4984166477058182 2.59072717378175e-05 0.2334015833314904 1.6960419166666617e-05 2.8326916666667166e-06 3.0720301276394584 0.1722707581293092
6 0.015625 6.893837299471083e-06 0.502450783118977 5.38967612103663e-05 0.23260542244712834 3.249555000000003e-05 5.385472500000018e-06 3.0766049080550206 0.4780528287268787
7 0.0078125 2.1039034253593456e-06 0.5019595585939423 0.0001168152876463202 0.2314218434076955 6.347387916666652e-05 1.0174979999999975e-05 3.0660112853736345 0.05847547955811578
8 0.00390625 -2.8110932915909705e-05 0.4986478587674269 0.00026531585038464895 0.23033601731379755 0.0001267744883333333 1.876201333333333e-05 3.055173448679726 0.38796885687566474
9 0.001953125 2.0431240675377005e-05 0.49905751453503916 0.0006390112282907606 0.22817748226639847 0.0002530849641666667 3.6188394166666645e-05 3.023540100742862 0.04572609173820361
10 0.0009765625 0.0001729255871063982 0.49964730991390777 0.0016466546101876142 0.22438108876169333 0.0005007756475000001 7.382670583333326e-05 3.0396939997114756 0.04852675992697055
11 0.00048828125 0.0003835680667899413 0.4993025618407165 0.004304065491031923 0.21835334222557967 0.001019747358333333 0.00014720180833333317 2.9969562638080514 0.0835491905925907
12 0.000244140625 7.118416462858983e-05 0.5003416618555554 0.010268428354506521 0.21278455382489486 0.0020333617766666668 0.00027338702500000027 3.021334461979972 0.10852032581983767
13 0.0001220703125 -0.00011416910054830147 0.4982729957740362 0.020195695396412503 0.20910968068073166 0.0040434879425 0.0005991542499999994 3.0071806503879386 0.21277421300585972
14 6.103515625e-05 -0.0006013268791460562 0.5007882379016314 0.030350439695859977 0.20743988144670306 0.008191885174166667 0.0010397092991666663 2.9863023560339665 0.3310813508507559
15 3.0517578125e-05 0.00026743273277759024 0.49793990593095455 0.03275905946856526 0.2126028136558203 0.015859194865833332 0.0020749278466666663 3.022853567390389 0.32780384227460335
16 1.52587890625e-05 -7.146197633614332e-05 0.49769212037537947 0.026858458909397306 0.2185836110372907 0.030895481098333327 0.0037794667074999987 3.0017249467738636 0.018636181299590028

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.0009 ***
*********************************************************
alpha = 1.9039283383437653 (exponent for weak convergence) 
beta = 0.28651740910468915 (exponent for variance of bias estimate) 
gamma = 0.9620763083243621 (exponent for cost of bias estimate) 

*********************************************************
*** MLMC complexity test ***
*********************************************************
 e2 value mlmc_cost N_l dt 
---------------------------------------------------------
 0.01 0.5653648043862749 297.77010990000167 [2240   32   16   16] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 0.005 0.4551646891307046 514.0888591999994 [5136   64   40   32] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 0.0025 0.5219956989491522 557.8154511000009 [8184  144  112   64] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 0.00125 0.5262414317947222 642.5556878 [16056   312   160    80] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 0.000625 0.5023751516828976 586.4636156000004 [20584   528   312   296] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 0.0003125 0.4973011329504014 709.8349630000005 [34368   968   648   440] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 0.00015625 0.49959732131711226 643.7671599999995 [45136  2040  1480  1064] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 7.8125e-05 0.4987123879145642 841.0698114999993 [76600  4008  2504  2160] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 3.90625e-05 0.4996021767121554 954.2640028000017 [133400   8384   7568   3568] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 1.953125e-05 0.4995639637823093 1749.8617792000014 [229184  17344  11936   5672] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 9.765625e-06 0.4974181912118643 2688.826772500007 [519480  33848  22056  12224] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 4.8828125e-06 0.5008084481942794 4095.272116699999 [742592  66648  44320  25008] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 2.44140625e-06 0.5003561037609857 9649.944514300003 [2534200  132056   90576   54024] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 

