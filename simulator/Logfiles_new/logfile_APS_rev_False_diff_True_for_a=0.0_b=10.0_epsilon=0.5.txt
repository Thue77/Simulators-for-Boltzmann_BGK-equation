
*********************************************************
***Python ml_test for APS method on 17-May-2021 19:57:01         ***
***    Altered diffusive coefficient is used!!      ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[10.] and eps = 0.5  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 120000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.4990494037416327 0.0 0.23480657639019678 0.0 7.040158333332751e-07 0.0 0.0
1 0.5 -2.096852761192761e-05 0.5014351617419109 0.0024939494253560764 0.23180787299273048 9.128841666666314e-07 6.15088333333406e-07 2.9684083442079006 0.27353587158026227
2 0.25 8.782379668516149e-05 0.503090491785851 0.004835500216004183 0.2282664197377673 8.726699999999828e-07 7.730116666666713e-07 3.372172826529365 0.1759375315143304
3 0.125 -0.00015130873277989471 0.5006055314049795 0.008901426772289169 0.22443885648859035 1.2487049999999538e-06 1.0658474999999612e-06 3.5730908866201183 0.25764866427490435
4 0.0625 0.0002846594962323556 0.5000762787641297 0.015166247125895111 0.21720502770387162 2.0655475000001054e-06 1.724658333333314e-06 3.7956400921644478 0.08841634219105417
5 0.03125 -0.0004375177273567038 0.5017816169966449 0.02239439209398321 0.21420794631733509 3.729510833333194e-06 2.2617975000001066e-06 4.202498541704501 0.22942019579163647
6 0.015625 0.0008252299253623267 0.4996342089968558 0.027200770572896417 0.21547082904922568 7.106698333333424e-06 4.192917499999993e-06 4.603405323010229 0.3143491030865649
7 0.0078125 0.0003132202223760026 0.49993784818830644 0.026702907195348728 0.220564794875535 1.20197725e-05 7.643433333333446e-06 5.717413739549623 0.0010082755648716777
8 0.00390625 -0.0003518822844084896 0.49999790493397156 0.020656601934856442 0.2249208714262265 2.114616333333341e-05 1.4972625833333275e-05 7.7286151543427986 0.043734373688646064
9 0.001953125 -0.00034716236653074763 0.5015308138572907 0.013348533432536192 0.23126984953456176 4.027761583333339e-05 2.9419370833333442e-05 10.617830804909698 0.20275713993082303
10 0.0009765625 -7.138101056548674e-05 0.5005281707991619 0.007683747505920951 0.23395163030291682 7.528534333333337e-05 5.915617499999997e-05 18.70977509291966 0.10219350387748544
11 0.00048828125 4.86313268315716e-05 0.49619336498615507 0.004147554078712462 0.23578227034134275 0.0001494964741666666 0.00011762156749999999 31.827155333304177 0.48967277917432805
12 0.000244140625 7.719725195267194e-05 0.49984018117705564 0.002150983904135039 0.23707991423207328 0.00029328173333333335 0.0002341140325000001 74.01726972119185 0.4045536452818527
13 0.0001220703125 -5.302142986033821e-05 0.5027392962106769 0.0010491212814674575 0.2371412168404297 0.0005887851600000001 0.00047723658833333335 103.19607908929436 0.33875928697461294
14 6.103515625e-05 6.889155926149528e-05 0.49984168759549313 0.0005418514721440215 0.23618561000568106 0.0011727222641666666 0.0009395393133333334 298.4422547220126 0.34383527527309754
15 3.0517578125e-05 5.4839430100872074e-05 0.49796891651422437 0.00029747594249798754 0.23860341111866393 0.002338530206666667 0.0018698601025 614.2236382132662 0.224442527936004
16 1.52587890625e-05 3.604277230077658e-05 0.501004835762257 0.0001412520705865948 0.23826083858061964 0.0046597087575000005 0.0037694812766666673 912.6671371938767 0.3504346115958206

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.25 ***
*********************************************************
alpha = 0.35838484174321467 (exponent for weak convergence) 
beta = 0.8700932232792381 (exponent for variance of bias estimate) 
gamma = 0.9642690123310379 (exponent for cost of bias estimate) 

*********************************************************
*** MLMC complexity test ***
*********************************************************
 e2 value mlmc_cost N_l dt 
---------------------------------------------------------
 0.01 0.45927283571934546 2.5557003000000122 [376  64  64  32  16  16  16  16  16] [2.500000e-02 1.250000e-02 6.250000e-03 3.125000e-03 1.562500e-03
 7.812500e-04 3.906250e-04 1.953125e-04 9.765625e-05] 
 0.005 0.5174147175446322 0.7188724999997476 [1240  112   64   48   32   32] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125] 
 0.0025 0.44426410157753504 20.321085799999764 [7712  616  360  216  104   64   16   16   32   16   16   16] [2.50000000e-02 1.25000000e-02 6.25000000e-03 3.12500000e-03
 1.56250000e-03 7.81250000e-04 3.90625000e-04 1.95312500e-04
 9.76562500e-05 4.88281250e-05 2.44140625e-05 1.22070313e-05] 
 0.00125 0.4990315060958824 1.7433663999994449 [9560  936  488  240  144   40   32] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125
 0.00039063] 
 0.000625 0.48264949424522663 7.0906387999998515 [24440  3808  1568   832   264    80    48    16    16    16] [2.5000000e-02 1.2500000e-02 6.2500000e-03 3.1250000e-03 1.5625000e-03
 7.8125000e-04 3.9062500e-04 1.9531250e-04 9.7656250e-05 4.8828125e-05] 
 0.0003125 0.49915736791986565 13.46863270000108 [56728  8024  3968  1936   592   336    80   128    16    16    16] [2.50000000e-02 1.25000000e-02 6.25000000e-03 3.12500000e-03
 1.56250000e-03 7.81250000e-04 3.90625000e-04 1.95312500e-04
 9.76562500e-05 4.88281250e-05 2.44140625e-05] 
 0.00015625 0.5124860235696395 18.878631799999994 [95136 18272 10960  4920  1600   576   216    64    32    16    16] [2.50000000e-02 1.25000000e-02 6.25000000e-03 3.12500000e-03
 1.56250000e-03 7.81250000e-04 3.90625000e-04 1.95312500e-04
 9.76562500e-05 4.88281250e-05 2.44140625e-05] 
 7.8125e-05 0.4952379089910915 1.0939834000002975 [53784 12232  6160  3856   488] [0.025     0.0125    0.00625   0.003125  0.0015625] 
 3.90625e-05 0.49639183338387755 324.2151488000003 [629592 140384  97408  57592  24504   9208   2088   1664    304     48
    296     16     16     16     16     16] [2.50000000e-02 1.25000000e-02 6.25000000e-03 3.12500000e-03
 1.56250000e-03 7.81250000e-04 3.90625000e-04 1.95312500e-04
 9.76562500e-05 4.88281250e-05 2.44140625e-05 1.22070313e-05
 6.10351563e-06 3.05175781e-06 1.52587891e-06 7.62939453e-07] 
 1.953125e-05 0.4979850155261472 3.291976899999952 [246208  52984  39200  20544   4320] [0.025     0.0125    0.00625   0.003125  0.0015625] 
 9.765625e-06 0.5011377881774178 16.408535600000278 [502616 116000  76920  47176  25216  10648   4832   1120] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125
 0.00039063 0.00019531] 
 4.8828125e-06 0.4997668937424665 3.4836470000003037 [283552  66248  45160  26872] [0.025    0.0125   0.00625  0.003125] 
 2.44140625e-06 0.5000262915276502 36.52682530000044 [2216120  581712  413648  257864  136264   26552] [0.025      0.0125     0.00625    0.003125   0.0015625  0.00078125] 

