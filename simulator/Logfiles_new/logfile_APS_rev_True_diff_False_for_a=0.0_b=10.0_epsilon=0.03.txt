
*********************************************************
***Python ml_test for APS method on 17-May-2021 21:02:22         ***
***    Reverse splitting is used!!      ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[10.] and eps = 0.03  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 120000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.499482160667163 0.0 0.23180383011046118 0.0 8.37724166666535e-07 0.0 0.0
1 0.5 -0.0009707080246915697 0.5004070163875747 0.07806017174053931 0.23200997940758156 2.2046516666665756e-06 6.281716666666881e-07 7.274590366996981 0.17615785559225455
2 0.25 -0.00012187379652396029 0.49836721292244907 0.07846145574369882 0.23316818058775624 2.4568366666666583e-06 7.394291666667978e-07 5.028248588927094 0.17793104946021218
3 0.125 0.000228492047412874 0.5024887183690723 0.07777103770299457 0.231511584099806 5.161426666666695e-06 1.0790983333333652e-06 4.023454020630544 0.36167374131371466
4 0.0625 0.0009882197549384087 0.5006667108393228 0.0781426463837087 0.23329500004349224 8.002538333333339e-06 1.6526924999999674e-06 3.520811065733994 0.2609120933137468
5 0.03125 0.0002406260144525306 0.4982340746936269 0.07786469341305137 0.23118003637473014 1.6867559166666623e-05 2.919337500000019e-06 3.2753173876571444 0.24836393178522576
6 0.015625 -0.000892851599225706 0.5000166713784703 0.07810320941387276 0.23235924023156496 3.127741249999989e-05 5.411591666666796e-06 3.1396477529978513 0.24867560252438367
7 0.0078125 0.00022693510023671159 0.5006402099218099 0.0774887108553015 0.23259964803484673 6.224118416666666e-05 1.0602415833333368e-05 3.0718254945836727 0.036852157737092016
8 0.00390625 0.00021710737035305282 0.4999915342681643 0.07632873741764393 0.22930380076542506 0.0001264359908333333 1.8959796666666643e-05 3.0684718659326857 0.08079074085216764
9 0.001953125 4.004422866173822e-05 0.5005215540234905 0.07490867479483282 0.22926678913445336 0.00024963415 3.661497833333331e-05 3.0296617472755547 0.045946814727020405
10 0.0009765625 -0.0004326615374949161 0.4996926577305177 0.07176299613206392 0.2254966067459214 0.0005125935108333334 7.173460916666675e-05 3.0204236193707827 0.0374544904490832
11 0.00048828125 0.0006033405182206635 0.49872775544788867 0.06796766866418102 0.22055492027293325 0.0010025239833333336 0.00013305774083333322 2.999695599736903 0.15025267856486535
12 0.000244140625 -0.0003703206935645423 0.49849009156853225 0.06305620126117378 0.21231942974239307 0.002002101835 0.0002943881516666662 3.010055911259121 0.012964518107925583
13 0.0001220703125 0.0005399095356152373 0.501141253721139 0.059315187374509075 0.2084162269109885 0.004100229011666666 0.00056122613 3.0030034007920645 0.2100060044900227
14 6.103515625e-05 -0.0002776356642000802 0.500463808594055 0.053503361682158274 0.20990798206552924 0.008042527803333331 0.0010812542383333333 3.014681920938759 0.04028478918336948
15 3.0517578125e-05 0.0003501213057929827 0.4989089397348761 0.04390502887606865 0.21435297949529708 0.0158455492175 0.0021268782800000006 2.9981936342749367 0.1945468789125587
16 1.52587890625e-05 6.860844131714021e-05 0.49884322878965937 0.03125452290139442 0.21859099488542524 0.03134362620916667 0.0038676577150000033 2.9968618464835566 0.01400680565076351

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.0009 ***
*********************************************************
alpha = 2.351396860140285 (exponent for weak convergence) 
beta = 0.4903212152969491 (exponent for variance of bias estimate) 
gamma = 0.984094432472744 (exponent for cost of bias estimate) 

*********************************************************
*** MLMC complexity test ***
*********************************************************
 e2 value mlmc_cost N_l dt 
---------------------------------------------------------
 0.01 0.44405802782085746 383.88499189999993 [2736   56   32   16] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 0.005 0.5138418511035483 576.5527459999992 [6016   80   56   32] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 0.0025 0.5296983048471897 802.477666699999 [12152   248   104    56] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 0.00125 0.4687787017296906 718.1361305999994 [16008   368   216   112] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 0.000625 0.503704714930139 871.6719759000022 [25728   920   432   200] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 0.0003125 0.513827774609141 702.3309379000004 [35216  1800   768   408] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 0.00015625 0.5082859664189112 671.4130133000001 [46856  3040  1752   968] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 7.8125e-05 0.5006367678566658 1046.8749577999997 [94832  6816  3512  1440] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 3.90625e-05 0.49545222952603785 1224.7177698999994 [180688  11008  10616   5520] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 1.953125e-05 0.5014441593322712 1714.7773469999995 [349880  24272  12944   9136] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 9.765625e-06 0.4976821679203388 3126.4471855000006 [870040  45608  27120  14512] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 4.8828125e-06 0.5008029875285562 4860.083222700005 [840888  90288  54192  29064] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 
 2.44140625e-06 0.5004325737352014 12459.198994300003 [3134592  207360  134480   70880] [9.000e-05 4.500e-05 2.250e-05 1.125e-05] 

