
*********************************************************
***Python ml_test for APS method on 24-May-2021 12:33:14         ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[1.] and eps = 0.32  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 1200000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.5004670185345262 0.0 1.921737099395705 0.0 5.902945833333521e-07 0.0 0.0
1 0.5 -0.0004345378199373655 0.498887010387186 0.453988000337546 1.8588871355391527 1.00750866666667e-06 6.27935500000003e-07 9.223378544143703 0.12217644313947615
2 0.25 0.001178432103088344 0.5009367857042647 0.4770632330091231 1.7610825258821314 1.3725353333333305e-06 8.386581666666674e-07 6.771506950067791 0.09410055387028542
3 0.125 0.0008715638698973989 0.5004865437944946 0.45575164944302243 1.6942690702566066 2.121824666666677e-06 1.265064916666668e-06 6.035399209191791 0.1460912627421575
4 0.0625 0.0002154515295399159 0.4991820693923025 0.38952065877923214 1.6655073709802375 3.6555799166666604e-06 2.0475224999999913e-06 7.089590102172235 0.1725579394078598
5 0.03125 0.0007796855451241987 0.497283656110951 0.2961580370830346 1.6969683777005702 6.596923666666659e-06 3.7358760000000045e-06 10.384912250956786 0.311689638131078
6 0.015625 -0.0003110245852712112 0.5014663879162031 0.19743120999069194 1.7377330937661102 1.2429226666666662e-05 7.07704508333333e-06 17.149207186431 0.5353210269597393
7 0.0078125 0.00010425376285205794 0.5015968622608745 0.11877398020255218 1.7806667390653854 2.432469841666667e-05 1.379898716666668e-05 31.60322856564548 0.003194360278161811
8 0.00390625 0.00015957732018967427 0.49869578451119084 0.06589815807151826 1.8004578418368558 4.756056316666667e-05 2.724027866666667e-05 62.563293979987286 0.3810495586813222
9 0.001953125 -0.00011054122800868441 0.49918167249695156 0.03426506681998457 1.8114674695728659 9.503599391666665e-05 5.41396040833333e-05 117.59891113770514 0.07580864800086762
10 0.0009765625 0.00019586665509447094 0.500263082318458 0.017878501634931144 1.8193509586035965 0.00018815787700000001 0.00010863801908333331 228.4163903892126 0.11432215108898817
11 0.00048828125 6.050601470116786e-07 0.4998071713257177 0.00907321601839855 1.8215759512050242 0.00037511304158333335 0.00021672363066666678 429.2441968979144 0.05966762652830399
12 0.000244140625 -7.150047566255253e-05 0.5007446429189257 0.004633156251591046 1.8208992834205242 0.00076565307425 0.0004325132895000001 994.9459536323892 0.13314309014649947
13 0.0001220703125 -1.5082175759029282e-06 0.49996472556691035 0.002176133194192134 1.8268158317367607 0.0015031605731666666 0.0008937733284166662 1618.5870729901012 0.1034463847608919
14 6.103515625e-05 -3.7501398650561054e-05 0.49937874659592957 0.0011618883955344466 1.829079118853625 0.0031269698157500004 0.0018490714215 3138.7808545176185 0.07314354424689816
15 3.0517578125e-05 -2.3897015625806884e-05 0.4993955660302904 0.0005409741511760432 1.8331454403379923 0.0064575852035 0.003744533327666667 5069.964384226212 0.005446724770374059
16 1.52587890625e-05 -3.0254480564200818e-05 0.5018076533965834 0.0003005443121070059 1.8257914075429926 0.013104569203249998 0.008442724795166666 11668.304808674806 0.32757387003402477

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.1024 ***
*********************************************************
alpha = 0.4862227268735158 (exponent for weak convergence) 
beta = 0.9334414658972902 (exponent for variance of bias estimate) 
gamma = 0.9989005899844657 (exponent for cost of bias estimate) 

