
*********************************************************
***Python ml_test for APS method on 24-May-2021 18:42:56         ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[5.1] and eps = 0.32  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 1200000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.5015242163452931 0.0 2.206269450537061 0.0 6.100263333333385e-07 0.0 0.0
1 0.5 -0.000284027704383185 0.5005192762031695 0.7382405318249943 1.3754178533498962 1.0755671666666681e-06 7.07391916666668e-07 13.33026680428927 0.07484058415297679
2 0.25 -0.0006842571943509216 0.49981345238206015 0.49906282082889286 0.9277402545192086 1.5456952499999943e-06 9.441513333333518e-07 10.282291076845016 0.002770534422941292
3 0.125 0.0004828177078266341 0.50009371755502 0.357633737937265 0.6885649976779747 2.4015416666666725e-06 1.4201449166666732e-06 7.235669220549344 0.030933182953063028
4 0.0625 -0.0009948141775152901 0.49916215487380494 0.2660540312202228 0.5501703981112596 4.099549000000013e-06 2.3778414166666728e-06 5.342786042146635 0.011064901962344751
5 0.03125 0.00011475171362484219 0.4986617890379929 0.206655402094354 0.461530581142399 7.641647583333342e-06 4.432989500000009e-06 4.475557562393614 0.11974756707055555
6 0.015625 4.647103300286568e-05 0.5005395137993532 0.1695528454832925 0.40355986752599454 1.4797811416666663e-05 8.439898000000005e-06 4.5743650847499016 0.3873276289866805
7 0.0078125 0.0002443965476710803 0.4997423558837677 0.14273161906846427 0.3682532501293566 2.8886938250000003e-05 1.651710683333334e-05 5.578509845979859 0.23478100045722325
8 0.00390625 -5.9878273032640635e-06 0.5005380259418065 0.11842257861308932 0.35064610394952317 5.670728416666667e-05 3.258440858333334e-05 7.353024587363165 0.1896964506672996
9 0.001953125 -0.00012905901880440888 0.500081075258486 0.09332275975822214 0.3427711043245164 0.00011214223041666666 6.593551083333327e-05 9.94456373541905 0.08072851049760252
10 0.0009765625 9.080106843283815e-05 0.4996840510165449 0.07023243792848922 0.3400641862006757 0.00022504038325000001 0.000132041009 13.839637089111548 0.12424999107029652
11 0.00048828125 8.13263578759014e-05 0.5003036620031179 0.05119925795644295 0.33881049909509875 0.0004555130761666667 0.00026645231858333336 18.792307571806493 0.14125344624147504
12 0.000244140625 3.4272872482919563e-06 0.500074388459103 0.036892515760553954 0.33846747321539544 0.0009134871452499999 0.0005181630474166667 25.018340309730117 0.06266580648832057
13 0.0001220703125 0.0002523556955968994 0.5000691033882766 0.026135554394476436 0.3381227018764159 0.0018215601864166669 0.0009715105499166669 30.688923288299456 0.07100546360191137
14 6.103515625e-05 -0.00013472463956022224 0.500500194867929 0.018764770525116777 0.3379801626464235 0.0036232286600833335 0.0019765776430833333 41.26875725952832 0.15894931955809177
15 3.0517578125e-05 -0.00011608703102131218 0.5006750110068351 0.013403365701253089 0.3380461668540525 0.007238923222083334 0.0037904130742499992 58.62405287569429 0.08308063379006793
16 1.52587890625e-05 3.017809675909813e-05 0.49937889344239444 0.009563095997077789 0.3387675058040024 0.01380652793575 0.007981131358583334 72.42996175371242 0.3839812091177318

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.1024 ***
*********************************************************
alpha = -0.017852868627029016 (exponent for weak convergence) 
beta = 0.44498343542780405 (exponent for variance of bias estimate) 
gamma = 0.9951706573137319 (exponent for cost of bias estimate) 

