
*********************************************************
***Python ml_test for APS method on 24-May-2021 10:50:19         ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[1.] and eps = 1.0  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 1200000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.5016673434339821 0.0 1.2850770368456013 0.0 5.871996666666668e-07 0.0 0.0
1 0.5 0.000675680298571966 0.5000961991819854 0.17087164102719468 1.0685193438633926 1.0735706666666603e-06 6.749387499999967e-07 9.74637890956557 0.3179112791955669
2 0.25 0.000255243320537397 0.5004201261079926 0.10903382994749103 0.9298236737539284 1.401577750000005e-06 8.9051583333332e-07 8.707354284751043 0.0107722904019555
3 0.125 0.00039609097979760555 0.49868750468300405 0.062219723809779755 0.8501630387965899 2.2375086666666633e-06 1.3066566666666605e-06 12.766537318520726 0.363944248353111
4 0.0625 -0.0001792934387439652 0.5010263224049583 0.03284278363938619 0.8084382984400289 3.6934715000000117e-06 2.199902583333332e-06 25.64852849914964 0.4591909253950089
5 0.03125 4.348604746178238e-05 0.5000584794428231 0.01682960819746249 0.7884682789162338 6.701258750000013e-06 3.870925750000005e-06 55.21225721504328 0.1926552655926703
6 0.015625 8.893644819579573e-05 0.5011734426737231 0.008471759485509345 0.7775886643672187 1.2860313083333329e-05 7.425212833333331e-06 104.97376465410657 0.20123005505419211
7 0.0078125 1.4919999812172034e-05 0.5006246788539892 0.00426506560734169 0.7729739090094393 2.4940734583333335e-05 1.3670877249999992e-05 209.68472982840464 0.1127018967527275
8 0.00390625 -4.853141720162881e-05 0.5010544348540832 0.002166046516211138 0.7695463668407725 4.7862929333333335e-05 2.733590608333331e-05 502.701709997236 0.09686575949952181
9 0.001953125 2.0904320470736772e-05 0.4990758337863038 0.0010374904879179505 0.7710139079924836 9.388147625000003e-05 5.3942681666666676e-05 810.3108882850352 0.4084515540641791
10 0.0009765625 1.5597613647820268e-05 0.5015786270125763 0.00054579638005485 0.7686766348589789 0.00018757146850000004 0.00010749389775 2434.69364056797 0.5107448551547857
11 0.00048828125 -1.0780313233580495e-05 0.5005764992786826 0.00027274700104385705 0.768742867715424 0.0003798304809166667 0.00021417415100000005 3580.4265107903284 0.20450923273739088
12 0.000244140625 1.1697025076854638e-05 0.500087672588773 0.00014824230101960763 0.7676546795525119 0.0007445214705 0.00043816994808333344 10808.40755873996 0.10354310402487421
13 0.0001220703125 8.623759426055457e-07 0.4989331246735432 7.30637021370901e-05 0.7679935761325032 0.0015266134682500002 0.0008735477314166667 14968.44769406907 0.23956956402568683
14 6.103515625e-05 -8.110395049555452e-07 0.4991419082510163 4.359622639841247e-05 0.7686369690191278 0.0030339423556666662 0.0017470863073333327 48920.57747846418 0.04349277577659153
15 3.0517578125e-05 -4.015661110596371e-06 0.5001138046419469 1.558112676893336e-05 0.7705370550254191 0.006083623801833334 0.0034848453615 39622.264484350366 0.20264939006671676
16 1.52587890625e-05 4.3874772405309105e-06 0.5001622117638099 6.580716580602915e-06 0.7686133424870547 0.012123732991916667 0.006992377459083333 15827.11345836353 0.009147995321083869

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 1.0 ***
*********************************************************
alpha = 0.5489353521884804 (exponent for weak convergence) 
beta = 0.98750730466326 (exponent for variance of bias estimate) 
gamma = 0.9540468256639594 (exponent for cost of bias estimate) 

