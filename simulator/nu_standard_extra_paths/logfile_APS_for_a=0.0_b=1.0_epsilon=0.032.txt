
*********************************************************
***Python ml_test for APS method on 24-May-2021 16:07:19         ***

*********************************************************
*** Experiemnt setup  ***
*** S(x,v) = 1/sqrt(2*pi)*v^2*e^{-v^2/2}*(1+cos(2*pi*(x+1/2))) ***
*** r(x) = ax+b, with a=[0.], b=[1.] and eps = 0.032  ***
*** Quantity of interest is F(X) = X  ***
*** No boundary conditions  ***
*********************************************************
Convergence tests, kurtosis, telescoping sum check 
*** using 1200000 samples and 17 levels ***
 l dt^f mean(F(X^f)-F(X^c)) mean(F(X^c))  var(F(X^f)-F(X^c)) var(F(X^c)) cost(F(X^f)-F(X^c)) cost(F(X)) kurtosis consistency 
---------------------------------------------------------
0 1.0 0.0 0.4977191874894504 0.0 2.0375826752332986 0.0 6.263062500000061e-07 0.0 0.0
1 0.5 -0.0002075144827424092 0.4995379275693339 0.5291404941448687 2.024612664449229 1.0850238333333332e-06 6.646291666666689e-07 9.276402564601106 0.20680144432409733
2 0.25 -0.0007633116679381464 0.4993490914891408 0.6232546801799856 2.0281758187342738 1.5388833333333333e-06 8.7368925000001e-07 6.547948145774745 0.057684358536584185
3 0.125 -0.001216768382042681 0.49807333557995503 0.6740341369101489 2.028036304514095 2.3538983333333204e-06 1.3183635833333321e-06 4.837128285130943 0.005870227159773742
4 0.0625 0.0003250144125787138 0.4977061751546615 0.6947915940133588 2.0183516870549525 3.979826250000009e-06 2.162522416666667e-06 3.9319986985528113 0.06871248617910564
5 0.03125 0.00056048150775047 0.49847118370916754 0.7004334742662242 2.000944221610716 7.294735083333338e-06 3.893287249999998e-06 3.4646832364335274 0.020337581014170256
6 0.015625 -0.0007167701450385692 0.4983837746574005 0.6977069966013858 1.971851535143068 1.4324312333333337e-05 7.3527797500000014e-06 3.250650146420225 0.06289169789654032
7 0.0078125 -2.1661912415069342e-05 0.4987809803707012 0.6765671999863663 1.9315212038540717 2.9537277500000004e-05 1.4584665499999995e-05 3.1286164981811635 0.042291303534300065
8 0.00390625 -0.0017452733698616124 0.5014501563297984 0.6411929114648268 1.8711637960667291 5.328758375e-05 2.9056413833333322e-05 3.086302746401134 0.45298729884087596
9 0.001953125 0.0008686261074952777 0.4989660191533419 0.5886416798872156 1.803581557212922 0.00010975451591666664 5.817394891666667e-05 3.0453373251588696 0.35198891758700074
10 0.0009765625 0.0007167500460104568 0.49770648745187207 0.5169989844724127 1.7806435465800672 0.00022403262541666668 0.00011632754166666667 3.0591298723918285 0.21247031494004634
11 0.00048828125 0.00015319752954605625 0.49974805756547486 0.4219374467589106 1.811895145142917 0.00044318313216666665 0.00023290709475 3.0723408797622724 0.20706535628832062
12 0.000244140625 0.00013252342435359524 0.49844083075859485 0.30921433249367414 1.8825993526738445 0.0008775725468333334 0.00046670070741666665 3.1190217479816056 0.16056440343565484
13 0.0001220703125 0.00022352892663239128 0.49948780136131044 0.20047322792209674 1.9310154776878692 0.0017054368712499997 0.0009412509649999999 3.230012550281233 0.09368589557690536
14 6.103515625e-05 -1.6620510717378185e-05 0.5002104531600777 0.11691920011616783 1.9792158249917018 0.0033304154200000003 0.0020409274757500003 3.462827698119213 0.08601354426009286
15 3.0517578125e-05 0.00022194238493243433 0.49928925681768715 0.06365870500943122 2.005667690345615 0.006842185359666666 0.003925905607416667 3.8959088851464942 0.13572851651174275
16 1.52587890625e-05 9.483821580943979e-05 0.49761217380825234 0.033239298181956416 2.0186407517694653 0.013546867027583334 0.008267483684583337 4.839048816081591 0.21429125966092222

*********************************************************

*** Linear regression estimates of MLMC paramters ***

*** regression is done for levels with dt << eps^2 = 0.001024 ***
*********************************************************
alpha = 0.14219641390411364 (exponent for weak convergence) 
beta = 0.7413933337528699 (exponent for variance of bias estimate) 
gamma = 0.9863921068313949 (exponent for cost of bias estimate) 

